{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature names: \n",
      "['count_of_Headline_unigram', 'count_of_unique_Headline_unigram', 'ratio_of_unique_Headline_unigram', 'count_of_Headline_bigram', 'count_of_unique_Headline_bigram', 'ratio_of_unique_Headline_bigram', 'count_of_Headline_trigram', 'count_of_unique_Headline_trigram', 'ratio_of_unique_Headline_trigram', 'count_of_articleBody_unigram', 'count_of_unique_articleBody_unigram', 'ratio_of_unique_articleBody_unigram', 'count_of_articleBody_bigram', 'count_of_unique_articleBody_bigram', 'ratio_of_unique_articleBody_bigram', 'count_of_articleBody_trigram', 'count_of_unique_articleBody_trigram', 'ratio_of_unique_articleBody_trigram', 'count_of_Headline_unigram_in_articleBody', 'ratio_of_Headline_unigram_in_articleBody', 'count_of_Headline_bigram_in_articleBody', 'ratio_of_Headline_bigram_in_articleBody', 'count_of_Headline_trigram_in_articleBody', 'ratio_of_Headline_trigram_in_articleBody', 'len_sent_Headline', 'len_sent_articleBody', 'fake_exist', 'fraud_exist', 'hoax_exist', 'false_exist', 'deny_exist', 'denies_exist', 'not_exist', 'despite_exist', 'nope_exist', 'doubt_exist', 'doubts_exist', 'bogus_exist', 'debunk_exist', 'pranks_exist', 'retract_exist']\n",
      "xBasicCounts.shape:\n",
      "(25413, 41)\n"
     ]
    }
   ],
   "source": [
    "from FeatureGenerator import *\n",
    "import ngram\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from helpers import *\n",
    "import hashlib\n",
    "\n",
    "class CountFeatureGenerator(FeatureGenerator):\n",
    "    def __init__(self, name='countFeatureGenerator'):\n",
    "        super(CountFeatureGenerator, self).__init__(name)\n",
    "    \n",
    "    def process(self, df):\n",
    "        grams = [\"unigram\", \"bigram\", \"trigram\"]\n",
    "        feat_names = [\"Headline\", \"articleBody\"]\n",
    "        print(\"generate counting features\")\n",
    "        \n",
    "        for feat_name in feat_names:\n",
    "            for gram in grams:\n",
    "                df[\"count_of_%s_%s\" % (feat_name, gram)] = list(df.apply(lambda x: len(x[feat_name + \"_\" + gram]), axis=1))\n",
    "                df[\"count_of_unique_%s_%s\" % (feat_name, gram)] = list(df.apply(lambda x: len(set(x[feat_name + \"_\" + gram])), axis=1))\n",
    "                df[\"ratio_of_unique_%s_%s\" % (feat_name, gram)] = list(map(try_divide, df[\"count_of_unique_%s_%s\"%(feat_name,gram)], df[\"count_of_%s_%s\"%(feat_name,gram)]))\n",
    "\n",
    "        # overlapping n-grams count\n",
    "        for gram in grams:\n",
    "                df[\"count_of_Headline_%s_in_articleBody\" % gram] = list(df.apply(lambda x: sum([1. for w in x[\"Headline_\" + gram] if w in set(x[\"articleBody_\" + gram])]), axis=1))\n",
    "                df[\"ratio_of_Headline_%s_in_articleBody\" % gram] = list(map(try_divide, df[\"count_of_Headline_%s_in_articleBody\" % gram], df[\"count_of_Headline_%s\" % gram]))\n",
    "\n",
    "        # number of sentences in headline and body\n",
    "        for feat_name in feat_names:\n",
    "            df['len_sent_%s' % feat_name] = df[feat_name].apply(lambda x: len(sent_tokenize(x)))\n",
    "        \n",
    "        \n",
    "        # dump the basic counting features into a file\n",
    "        feat_names = [ n for n in df.columns if \"count\" in n  or \"ratio\" in n or \"len_sent\" in n]\n",
    "        \n",
    "        # binary refuting features\n",
    "        _refuting_words = [\n",
    "            'fake',\n",
    "            'fraud',\n",
    "            'hoax',\n",
    "            'false',\n",
    "            'deny', 'denies',\n",
    "            # 'refute',\n",
    "            'not',\n",
    "            'despite',\n",
    "            'nope',\n",
    "            'doubt', 'doubts',\n",
    "            'bogus',\n",
    "            'debunk',\n",
    "            'pranks',\n",
    "            'retract'\n",
    "        ]\n",
    "\n",
    "        \n",
    "        check_words = _refuting_words\n",
    "        for rf in check_words:\n",
    "            fname = '%s_exist' % rf\n",
    "            feat_names.append(fname)\n",
    "            df[fname] = list(df['Headline'].map(lambda x: 1 if rf in x else 0))\n",
    "        \n",
    "\n",
    "        print('BasicCountFeatures:')\n",
    "        print(df)\n",
    "        \n",
    "        train = df[~df['target'].isnull()]\n",
    "        print('train:')\n",
    "        print(train[['Headline_unigram','Body ID', 'count_of_Headline_unigram']])\n",
    "        xBasicCountsTrain = train[feat_names].values\n",
    "        outfilename_bcf_train = \"train.basic.pkl\"\n",
    "        with open(outfilename_bcf_train, \"wb\") as outfile:\n",
    "            pickle.dump(feat_names, outfile, -1)\n",
    "            pickle.dump(xBasicCountsTrain, outfile, -1)\n",
    "        print('basic counting features for training saved in %s' % outfilename_bcf_train)\n",
    "        \n",
    "        test = df[df['target'].isnull()]\n",
    "        print('test:')\n",
    "        print(test[['Headline_unigram','Body ID', 'count_of_Headline_unigram']])\n",
    "        if test.shape[0] > 0:\n",
    "            # test set exists\n",
    "            print('saving test set')\n",
    "            xBasicCountsTest = test[feat_names].values\n",
    "            outfilename_bcf_test = \"test.basic.pkl\"\n",
    "            with open(outfilename_bcf_test, 'wb') as outfile:\n",
    "                pickle.dump(feat_names, outfile, -1)\n",
    "                pickle.dump(xBasicCountsTest, outfile, -1)\n",
    "                print('basic counting features for test saved in %s' % outfilename_bcf_test)\n",
    "            \n",
    "    def read(self, header='train'):\n",
    "        filename_bcf = \"%s.basic.pkl\" % header\n",
    "        with open(filename_bcf, \"rb\") as infile:\n",
    "            feat_names = pickle.load(infile)\n",
    "            xBasicCounts = pickle.load(infile)\n",
    "            print('feature names: ')\n",
    "            print(feat_names)\n",
    "            print('xBasicCounts.shape:')\n",
    "            print(xBasicCounts.shape)\n",
    "            np.save('counts_test', [xBasicCounts])\n",
    "        return [xBasicCounts]\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    cf = CountFeatureGenerator()\n",
    "    cf.read('test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
