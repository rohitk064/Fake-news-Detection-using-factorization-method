{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FeatureGenerator import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gensim\n",
    "from sklearn.preprocessing import normalize\n",
    "from helpers import *\n",
    "\n",
    "class Word2VecFeatureGenerator(FeatureGenerator):\n",
    "    def __init__(self, name='word2vecFeatureGenerator'):\n",
    "        super(Word2VecFeatureGenerator, self).__init__(name)\n",
    "        \n",
    "    def process(self, df):\n",
    "\n",
    "        print('generating word2vec features')\n",
    "        df[\"Headline_unigram_vec\"] = df[\"Headline\"].map(lambda x: preprocess_data(x, exclude_stopword=False, stem=False))\n",
    "        df[\"articleBody_unigram_vec\"] = df[\"articleBody\"].map(lambda x: preprocess_data(x, exclude_stopword=False, stem=False))\n",
    "        \n",
    "        n_train = df[~df['target'].isnull()].shape[0]\n",
    "        print('Word2VecFeatureGenerator: n_train:',n_train)\n",
    "        n_test = df[df['target'].isnull()].shape[0]\n",
    "        print('Word2VecFeatureGenerator: n_test:',n_test)\n",
    "        \n",
    "        # 1). document vector built by multiplying together all the word vectors\n",
    "        # using Google's pre-trained word vectors\n",
    "        model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "        print('model loaded')\n",
    "\n",
    "        Headline_unigram_array = df['Headline_unigram_vec'].values\n",
    "        print('Headline_unigram_array:')\n",
    "        print(Headline_unigram_array)\n",
    "        print(Headline_unigram_array.shape)\n",
    "        print(type(Headline_unigram_array))\n",
    "        \n",
    "        # word vectors weighted by normalized tf-idf coefficient?\n",
    "        #headlineVec = [0]\n",
    "        headlineVec = list(map(lambda x: reduce(np.add, [model[y] for y in x if y in model], [0.]*300), Headline_unigram_array))\n",
    "        headlineVec = np.array(headlineVec)\n",
    "        print('headlineVec:')\n",
    "        print(headlineVec)\n",
    "        print('type(headlineVec)')\n",
    "        print(type(headlineVec))\n",
    "        #headlineVec = np.exp(headlineVec)\n",
    "        print(headlineVec.shape)\n",
    "        headlineVec = normalize(headlineVec)\n",
    "        print('headlineVec')\n",
    "        print(headlineVec)\n",
    "        print(headlineVec.shape)\n",
    "        \n",
    "        headlineVecTrain = headlineVec[:n_train, :]\n",
    "        outfilename_hvec_train = \"train.headline.word2vec.pkl\"\n",
    "        with open(outfilename_hvec_train, \"wb\") as outfile:\n",
    "            pickle.dump(headlineVecTrain, outfile, -1)\n",
    "        print('headline word2vec features of training set saved in %s' % outfilename_hvec_train)\n",
    "\n",
    "        if n_test > 0:\n",
    "            # test set is available\n",
    "            headlineVecTest = headlineVec[n_train:, :]\n",
    "            outfilename_hvec_test = \"test.headline.word2vec.pkl\"\n",
    "            with open(outfilename_hvec_test, \"wb\") as outfile:\n",
    "                pickle.dump(headlineVecTest, outfile, -1)\n",
    "            print('headline word2vec features of test set saved in %s' % outfilename_hvec_test)\n",
    "        print('headine done')\n",
    "\n",
    "        Body_unigram_array = df['articleBody_unigram_vec'].values\n",
    "        print('Body_unigram_array:')\n",
    "        print(Body_unigram_array)\n",
    "        print(Body_unigram_array.shape)\n",
    "        #bodyVec = [0]\n",
    "        bodyVec = list(map(lambda x: reduce(np.add, [model[y] for y in x if y in model], [0.]*300), Body_unigram_array))\n",
    "        bodyVec = np.array(bodyVec)\n",
    "        print(bodyVec)\n",
    "        print(bodyVec.shape)\n",
    "        \n",
    "        bodyVec = normalize(bodyVec)\n",
    "        print('bodyVec')\n",
    "        print(bodyVec)\n",
    "        print(bodyVec.shape)\n",
    "\n",
    "        bodyVecTrain = bodyVec[:n_train, :]\n",
    "        outfilename_bvec_train = \"train.body.word2vec.pkl\"\n",
    "        with open(outfilename_bvec_train, \"wb\") as outfile:\n",
    "            pickle.dump(bodyVecTrain, outfile, -1)\n",
    "        print('body word2vec features of training set saved in %s' % outfilename_bvec_train)\n",
    "        \n",
    "        if n_test > 0:\n",
    "            # test set is available\n",
    "            bodyVecTest = bodyVec[n_train:, :]\n",
    "            outfilename_bvec_test = \"test.body.word2vec.pkl\"\n",
    "            with open(outfilename_bvec_test, \"wb\") as outfile:\n",
    "                pickle.dump(bodyVecTest, outfile, -1)\n",
    "            print('body word2vec features of test set saved in %s' % outfilename_bvec_test)\n",
    "\n",
    "        print('body done')\n",
    "\n",
    "        res = []\n",
    "        for i in range(0, 75385):\n",
    "            res.append(cosine_sim(headlineVec[i], bodyVec[i]))\n",
    "        # compute cosine similarity between headline/body word2vec features\n",
    "        simVec = np.asarray(list(res))[:, np.newaxis]\n",
    "        print('simVec.shape:')\n",
    "        print(simVec.shape)\n",
    "\n",
    "        simVecTrain = simVec[:n_train]\n",
    "        outfilename_simvec_train = \"train.sim.word2vec.pkl\"\n",
    "        with open(outfilename_simvec_train, \"wb\") as outfile:\n",
    "            pickle.dump(simVecTrain, outfile, -1)\n",
    "        print('word2vec sim. features of training set saved in %s' % outfilename_simvec_train)\n",
    "        \n",
    "        if n_test > 0:\n",
    "            # test set is available\n",
    "            simVecTest = simVec[n_train:]\n",
    "            outfilename_simvec_test = \"test.sim.word2vec.pkl\"\n",
    "            with open(outfilename_simvec_test, \"wb\") as outfile:\n",
    "                pickle.dump(simVecTest, outfile, -1)\n",
    "            print('word2vec sim. features of test set saved in %s' % outfilename_simvec_test)\n",
    "\n",
    "        return 1\n",
    "    \n",
    "    def read(self, header='train'):\n",
    "\n",
    "        filename_hvec = \"%s.headline.word2vec.pkl\" % header\n",
    "        with open(filename_hvec, \"rb\") as infile:\n",
    "            headlineVec = pickle.load(infile)\n",
    "\n",
    "        filename_bvec = \"%s.body.word2vec.pkl\" % header\n",
    "        with open(filename_bvec, \"rb\") as infile:\n",
    "            bodyVec = pickle.load(infile)\n",
    "\n",
    "        filename_simvec = \"%s.sim.word2vec.pkl\" % header\n",
    "        with open(filename_simvec, \"rb\") as infile:\n",
    "            simVec = pickle.load(infile)\n",
    "\n",
    "        print('headlineVec.shape:')\n",
    "        print(headlineVec.shape)\n",
    "        #print type(headlineVec)\n",
    "        print('bodyVec.shape:')\n",
    "        print(bodyVec.shape)\n",
    "        #print type(bodyVec)\n",
    "        print('simVec.shape:')\n",
    "        print(simVec.shape)\n",
    "        #print type(simVec)\n",
    "        np.save('word2vec_headline_body_train', [headlineVec, bodyVec])\n",
    "        return [headlineVec, bodyVec, simVec]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = Word2VecFeatureGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlineVec.shape:\n",
      "(49972, 300)\n",
      "bodyVec.shape:\n",
      "(49972, 300)\n",
      "simVec.shape:\n",
      "(49972, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[  5.35259352e-02,   1.32955500e-02,   9.87021049e-02, ...,\n",
       "          -5.21376449e-02,   7.17105366e-02,  -4.89572585e-03],\n",
       "        [  7.50404004e-02,   3.59492218e-02,  -9.60042341e-05, ...,\n",
       "          -5.12837163e-02,   4.00992231e-02,   1.19219803e-02],\n",
       "        [  9.64843133e-02,  -1.04772821e-02,  -5.52340203e-02, ...,\n",
       "          -2.13550719e-02,   5.99560063e-02,  -6.44642214e-03],\n",
       "        ..., \n",
       "        [  7.17788898e-02,  -1.76894229e-02,   7.37191665e-02, ...,\n",
       "          -1.04984853e-02,   9.00299718e-02,  -7.46042050e-03],\n",
       "        [ -1.37780814e-02,   5.00387097e-02,   1.75331500e-02, ...,\n",
       "          -4.76819626e-02,   5.50542048e-02,  -4.90198838e-02],\n",
       "        [  2.13743771e-02,   8.42956669e-02,   4.20932043e-03, ...,\n",
       "          -1.33208890e-01,  -1.60494717e-02,   4.23692253e-02]]),\n",
       " array([[ 0.03247191,  0.03348987,  0.04878961, ..., -0.03635329,\n",
       "          0.04725184, -0.00169143],\n",
       "        [ 0.04067834,  0.06328456,  0.03503142, ..., -0.04174063,\n",
       "          0.06769959, -0.00987635],\n",
       "        [ 0.03247841,  0.0596236 ,  0.0517613 , ..., -0.03465109,\n",
       "          0.06113989, -0.01327767],\n",
       "        ..., \n",
       "        [ 0.03961257,  0.01573018,  0.07511423, ..., -0.04345158,\n",
       "          0.08092605, -0.05160161],\n",
       "        [-0.01027013,  0.01112148,  0.02871667, ..., -0.06595363,\n",
       "          0.04836444, -0.05488853],\n",
       "        [ 0.03187888,  0.03801723,  0.02480395, ..., -0.05412919,\n",
       "          0.04389674, -0.02361483]]),\n",
       " array([[ 0.54240233],\n",
       "        [ 0.72038103],\n",
       "        [ 0.67975977],\n",
       "        ..., \n",
       "        [ 0.78604965],\n",
       "        [ 0.77248578],\n",
       "        [ 0.54469445]])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.read('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
